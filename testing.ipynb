{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Life Expectancy Data \n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# pd.options.display.max_rows = 100\n",
    "# pd.options.display.max_columns = 100\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/raw/'\n",
    "data_files = sorted(os.listdir(data_path))\n",
    "\n",
    "\n",
    "def get_column_names(df, keyword_fr, keyword_eng):\n",
    "    fr_idx = df.isin([keyword_fr]).any(axis=1).idxmax()\n",
    "    eng_idx = df.isin([keyword_eng]).any(axis=1).idxmax()\n",
    "    col_names = df.loc[[fr_idx, eng_idx], :].ffill().ffill(axis=1).iloc[1, 2:].tolist()\n",
    "    return col_names\n",
    "\n",
    "\n",
    "def df_cleaning(df):\n",
    "    drop_na_df = df.dropna(axis=1, how='all').dropna(axis=0, how='all').reset_index(drop=True)\n",
    "    query = ' '.join(drop_na_df.iloc[1, 10].split()[1:])\n",
    "    main_cols = [query, 'Participants/Percent'] + get_column_names(drop_na_df, 'Sexe', 'Gender')\n",
    "    sub_cols = ['-', '-'] + get_column_names(drop_na_df, 'Homme', 'Man')\n",
    "    first_row_idx = drop_na_df.isin(['TOTAL']).any(axis=1).idxmax()\n",
    "    clean_df = pd.DataFrame(drop_na_df.iloc[first_row_idx:].values, columns=[main_cols, sub_cols]).dropna(axis=1, how='all')\n",
    "\n",
    "    options = clean_df.iloc[1:, [0]]\n",
    "    ff_opts = options.ffill().T.values[0]\n",
    "\n",
    "    if len(options) % 2 != 0:\n",
    "        ff_opts = ff_opts[:-1]\n",
    "\n",
    "    if (ff_opts[::2] != ff_opts[1::2]).any():\n",
    "        ff_opts[::2] = ff_opts[1::2]\n",
    "\n",
    "    if len(options) % 2 != 0:\n",
    "        clean_df.iloc[1:-1, 0] = ff_opts\n",
    "        clean_df.iloc[-1, 0] = 'Average'\n",
    "    else:\n",
    "        clean_df.iloc[1:, 0] = ff_opts\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def save_df(path, df, name):\n",
    "    with open(path, 'w') as f:\n",
    "        df.to_csv(f, index=False)\n",
    "    print(f'df {name} cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"C1.csv\"\n",
    "# file_path = data_path + name\n",
    "# df = pd.read_csv(file_path, skipinitialspace=True)\n",
    "# clean_df = df_cleaning(df)\n",
    "# display(clean_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_path = 'data/clean/' + name + '_clean.csv'\n",
    "# save_df(clean_path, clean_df, name)\n",
    "# read_df = pd.read_csv(clean_path, header=[0, 1])\n",
    "# display(read_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df B2 cleaned\n",
      "df C1 cleaned\n",
      "df C14 cleaned\n",
      "df C2 cleaned\n",
      "df D1.1 cleaned\n",
      "df D1.2 cleaned\n",
      "df D1.3 cleaned\n",
      "df D10 cleaned\n",
      "df D11 cleaned\n",
      "df D112 cleaned\n",
      "df D15a.1 cleaned\n",
      "df D15a.2 cleaned\n",
      "df D15b.1 cleaned\n",
      "df D15b.2 cleaned\n",
      "df D25 cleaned\n",
      "df D40 cleaned\n",
      "df D40R cleaned\n",
      "df D40a cleaned\n",
      "df D40b cleaned\n",
      "df D40c cleaned\n",
      "df D43 cleaned\n",
      "df D43a cleaned\n",
      "df D43b cleaned\n",
      "df D46 cleaned\n",
      "df D60 cleaned\n",
      "df D62.1 cleaned\n",
      "df D62.2 cleaned\n",
      "df D62.3 cleaned\n",
      "df D62.4 cleaned\n",
      "df D62R cleaned\n",
      "df D63 cleaned\n",
      "df D7.1 cleaned\n",
      "df D7.2 cleaned\n",
      "df D7.3 cleaned\n",
      "df D70 cleaned\n",
      "df D71.1 cleaned\n",
      "df D71.2 cleaned\n",
      "df D71.3 cleaned\n",
      "df D72.1 cleaned\n",
      "df D72.2 cleaned\n",
      "df D73.1 cleaned\n",
      "df D73.2 cleaned\n",
      "df D77 cleaned\n",
      "df D78 cleaned\n",
      "df D79 cleaned\n",
      "df D8 cleaned\n",
      "df Q1NAT cleaned\n",
      "df QB1 cleaned\n",
      "df QB10 cleaned\n",
      "df QB11.1 cleaned\n",
      "df QB11.2 cleaned\n",
      "df QB11.3 cleaned\n",
      "df QB12 cleaned\n",
      "df QB13 cleaned\n",
      "df QB14 cleaned\n",
      "df QB1B2T cleaned\n",
      "df QB1R cleaned\n",
      "df QB2 cleaned\n",
      "df QB2R cleaned\n",
      "df QB3a cleaned\n",
      "df QB3a2 cleaned\n",
      "df QB3a2R cleaned\n",
      "df QB3aR cleaned\n",
      "df QB3b cleaned\n",
      "df QB3b2 cleaned\n",
      "df QB4a cleaned\n",
      "df QB4a2 cleaned\n",
      "df QB4a2R cleaned\n",
      "df QB4aR cleaned\n",
      "df QB4b cleaned\n",
      "df QB4b2 cleaned\n",
      "df QB5a cleaned\n",
      "df QB5aR cleaned\n",
      "df QB5b cleaned\n",
      "df QB5b2 cleaned\n",
      "df QB6 cleaned\n",
      "df QB6R cleaned\n",
      "df QB7 cleaned\n",
      "df QB8 cleaned\n",
      "df QB9 cleaned\n"
     ]
    }
   ],
   "source": [
    "# for file in data_files:\n",
    "#     name = file[:-4]\n",
    "#     file_path = data_path + file\n",
    "#     df = pd.read_csv(file_path, skipinitialspace=True)\n",
    "#     clean_df = df_cleaning(df)\n",
    "\n",
    "#     clean_path = 'data/clean/' + name + '_clean.csv'\n",
    "#     save_df(clean_path, clean_df, name)\n",
    "#     read_df = pd.read_csv(clean_path, header=[0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir = 'data/clean/'\n",
    "clean_paths = sorted(os.listdir(clean_dir))\n",
    "\n",
    "for path in clean_paths:\n",
    "    file_path = clean_dir + path\n",
    "    df = pd.read_csv(file_path, header=[0, 1])\n",
    "    query = df.columns.get_level_values(0)[0]\n",
    "    options = df.iloc[1:, 0].tolist()\n",
    "    print(f'file: {path}\\nquery: {query}\\noptions:\\n{options}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyeleven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
